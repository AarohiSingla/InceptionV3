{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.metrics: [<tensorflow.python.keras.metrics.BinaryAccuracy object at 0x000002BFA113A1D0>]\n",
      "current accuracy value: 1.0\n",
      "WARNING:tensorflow:Output predictions missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to predictions.\n",
      "Train on 3 samples\n",
      "3/3 [==============================] - 1s 293ms/sample - loss: 0.9531 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bfa1419b38>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "class LogisticEndpoint(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(LogisticEndpoint, self).__init__(name=name)\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "    def call(self, targets, logits, sample_weights=None):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        loss = self.loss_fn(targets, logits, sample_weights)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # Log accuracy as a metric and add it\n",
    "        # to the layer using `self.add_metric()`.\n",
    "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
    "        self.add_metric(acc, name=\"accuracy\")\n",
    "\n",
    "        # Return the inference-time prediction tensor (for `.predict()`).\n",
    "        return tf.nn.softmax(logits)\n",
    "\n",
    "layer = LogisticEndpoint()\n",
    "\n",
    "targets = tf.ones((2, 2))\n",
    "logits = tf.ones((2, 2))\n",
    "y = layer(targets, logits)\n",
    "\n",
    "print(\"layer.metrics:\", layer.metrics)\n",
    "print(\"current accuracy value:\", float(layer.metrics[0].result()))\n",
    "inputs = keras.Input(shape=(3,), name=\"inputs\")\n",
    "targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "logits = keras.layers.Dense(10)(inputs)\n",
    "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\n",
    "\n",
    "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
    "model.compile(optimizer=\"adam\")\n",
    "\n",
    "data = {\n",
    "    \"inputs\": np.random.random((3, 3)),\n",
    "    \"targets\": np.random.random((3, 10)),\n",
    "}\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Implementation of InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow verion 2.0 with keras 2.3 version\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "#from keras.models import Model\n",
    "#from keras.layers import Input\n",
    "#from keras.layers import Conv2D\n",
    "#from keras.layers import MaxPooling2D\n",
    "#from keras.layers.merge import concatenate\n",
    "#from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inception naive version\n",
    "\n",
    "def inception_module(x, f1, f2, f3):\n",
    "\t# 1x1 conv\n",
    "\tconv1 =  keras.layers.Conv2D(f1, (1,1), padding='same', activation='relu')(x)\n",
    "\t# 3x3 conv\n",
    "\tconv3 = keras.layers.Conv2D(f2, (3,3), padding='same', activation='relu')(x)\n",
    "\t# 5x5 conv\n",
    "\tconv5 = keras.layers.Conv2D(f3, (5,5), padding='same', activation='relu')(x)\n",
    "\t# 3x3 max pooling\n",
    "\tpool = keras.layers.MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n",
    "\t# concatenate filters\n",
    "\tout = keras.layers.merge.concatenate([conv1, conv3, conv5, pool])\n",
    "\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img_input = keras.Input(shape=(299, 299, 3))\n",
    "classes=1000\n",
    "#WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "#WEIGHTS_PATH = 'inception_v3_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "#WEIGHTS_PATH = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "channel_axis=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_bn(x,filters,num_row,num_col,padding='same',strides=(1, 1)):\n",
    "   \n",
    "    x = keras.layers.Conv2D(filters, (num_row, num_col),strides=strides,padding=padding)(x)\n",
    "    x = keras.layers.BatchNormalization(axis=3, scale=False)(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# num_row and num_cols are height and width of filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model layer by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_block_a(x):    \n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)  # 64 filters of 1*1\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)  #48 filters of 1*1\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
    "    x = keras.layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool], axis=channel_axis)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_block_a(x):  \n",
    "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = keras.layers.concatenate([branch3x3, branch3x3dbl, branch_pool],axis=channel_axis)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17 x 17 x 768\n",
    "def inc_block_b(x):\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = keras.layers.AveragePooling2D((3, 3), strides=(1, 1),padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = keras.layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool], axis=channel_axis)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed 8: 8 x 8 x 1280\n",
    "def reduction_block_b(x): \n",
    "    branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
    "    branch7x7x3 = conv2d_bn( branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = keras.layers.concatenate([branch3x3, branch7x7x3, branch_pool], axis=channel_axis)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_block_c(x):        \n",
    "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
    "\n",
    "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
    "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
    "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
    "        branch3x3 = keras.layers.concatenate([branch3x3_1, branch3x3_2],axis=channel_axis)\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
    "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
    "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
    "        branch3x3dbl = keras.layers.concatenate([branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n",
    "\n",
    "        branch_pool = keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = keras.layers.concatenate( [branch1x1, branch3x3, branch3x3dbl, branch_pool],axis=channel_axis)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = keras.Input(shape=(299, 299, 3))  #shape=(None, 299, 299, 3)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation_631/Identity:0\", shape=(None, 149, 149, 32), dtype=float32)\n",
      "Tensor(\"activation_632/Identity:0\", shape=(None, 147, 147, 32), dtype=float32)\n",
      "Tensor(\"activation_633/Identity:0\", shape=(None, 147, 147, 64), dtype=float32)\n",
      "Tensor(\"max_pooling2d_28/Identity:0\", shape=(None, 73, 73, 64), dtype=float32)\n",
      "Tensor(\"activation_634/Identity:0\", shape=(None, 73, 73, 80), dtype=float32)\n",
      "Tensor(\"activation_635/Identity:0\", shape=(None, 71, 71, 192), dtype=float32)\n",
      "Tensor(\"max_pooling2d_29/Identity:0\", shape=(None, 35, 35, 192), dtype=float32)\n",
      "Tensor(\"concatenate_96/Identity:0\", shape=(None, 35, 35, 256), dtype=float32)\n",
      "Tensor(\"concatenate_97/Identity:0\", shape=(None, 35, 35, 256), dtype=float32)\n",
      "Tensor(\"concatenate_98/Identity:0\", shape=(None, 35, 35, 256), dtype=float32)\n",
      "Tensor(\"concatenate_99/Identity:0\", shape=(None, 17, 17, 736), dtype=float32)\n",
      "Tensor(\"concatenate_100/Identity:0\", shape=(None, 17, 17, 768), dtype=float32)\n",
      "Tensor(\"concatenate_101/Identity:0\", shape=(None, 17, 17, 768), dtype=float32)\n",
      "Tensor(\"concatenate_102/Identity:0\", shape=(None, 17, 17, 768), dtype=float32)\n",
      "Tensor(\"concatenate_103/Identity:0\", shape=(None, 17, 17, 768), dtype=float32)\n",
      "Tensor(\"concatenate_104/Identity:0\", shape=(None, 8, 8, 1280), dtype=float32)\n",
      "Tensor(\"concatenate_107/Identity:0\", shape=(None, 8, 8, 2048), dtype=float32)\n",
      "Tensor(\"concatenate_110/Identity:0\", shape=(None, 8, 8, 2048), dtype=float32)\n",
      "Tensor(\"avg_pool_4/Identity:0\", shape=(None, 2048), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'predictions_5/Identity:0' shape=(None, 1000) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input image size: 299 x 299 x 3\n",
    "x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid') # 149 x 149 x 32\n",
    "x = conv2d_bn(x, 32, 3, 3, padding='valid')  # 147 x 147 x 32\n",
    "x = conv2d_bn(x, 64, 3, 3) # 147 x 147 x 64\n",
    "\n",
    "x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)   # 73  x 73 x 64\n",
    "x = conv2d_bn(x, 80, 1, 1, padding='valid') # 73 x 73 x 80\n",
    "x = conv2d_bn(x, 192, 3, 3, padding='valid')  # 71 x 71 x 192\n",
    "x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)  # 35 x 35 x 192\n",
    "\n",
    "\n",
    "x=inc_block_a(x) #35, 35, 256\n",
    "x=inc_block_a(x) #35, 35, 256\n",
    "x=inc_block_a(x) #35, 35, 256\n",
    "\n",
    "x=reduction_block_a(x) #17, 17, 736\n",
    "\n",
    "x=inc_block_b(x) #17, 17, 768\n",
    "x=inc_block_b(x) #17, 17, 768\n",
    "x=inc_block_b(x) #17, 17, 768\n",
    "x=inc_block_b(x) #17, 17, 768\n",
    "\n",
    "x=reduction_block_b(x) #shape=(None, 8, 8, 1280)\n",
    "\n",
    "x=inc_block_c(x) # shape=(None, 8, 8, 2048) \n",
    "x=inc_block_c(x) # shape=(None, 8, 8, 2048) \n",
    "\n",
    "x = keras.layers.GlobalAveragePooling2D(name='avg_pool')(x) # shape=(None, 2048)\n",
    "\n",
    "x = keras.layers.Dense(classes, activation='softmax', name='predictions')(x) #shape=(None, 1000) \n",
    "\n",
    "\n",
    "\n",
    "# Create model.\n",
    "inputs = img_input\n",
    "model =  keras.Model(inputs, x, name='inception_v3')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# plot model architecture\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True, to_file='inception_model_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 149, 149, 32) 896         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_631 (BatchN (None, 149, 149, 32) 96          conv2d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_631 (Activation)     (None, 149, 149, 32) 0           batch_normalization_631[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)             (None, 147, 147, 32) 9248        activation_631[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_632 (BatchN (None, 147, 147, 32) 96          conv2d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_632 (Activation)     (None, 147, 147, 32) 0           batch_normalization_632[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 147, 147, 64) 18496       activation_632[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_633 (BatchN (None, 147, 147, 64) 192         conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_633 (Activation)     (None, 147, 147, 64) 0           batch_normalization_633[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 73, 73, 64)   0           activation_633[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_634 (Conv2D)             (None, 73, 73, 80)   5200        max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_634 (BatchN (None, 73, 73, 80)   240         conv2d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_634 (Activation)     (None, 73, 73, 80)   0           batch_normalization_634[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)             (None, 71, 71, 192)  138432      activation_634[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_635 (BatchN (None, 71, 71, 192)  576         conv2d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_635 (Activation)     (None, 71, 71, 192)  0           batch_normalization_635[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, 35, 35, 192)  0           activation_635[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)             (None, 35, 35, 64)   12352       max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_639 (BatchN (None, 35, 35, 64)   192         conv2d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_639 (Activation)     (None, 35, 35, 64)   0           batch_normalization_639[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)             (None, 35, 35, 48)   9264        max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)             (None, 35, 35, 96)   55392       activation_639[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_637 (BatchN (None, 35, 35, 48)   144         conv2d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_640 (BatchN (None, 35, 35, 96)   288         conv2d_640[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_637 (Activation)     (None, 35, 35, 48)   0           batch_normalization_637[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_640 (Activation)     (None, 35, 35, 96)   0           batch_normalization_640[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_60 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_636 (Conv2D)             (None, 35, 35, 64)   12352       max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_638 (Conv2D)             (None, 35, 35, 64)   76864       activation_637[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_641 (Conv2D)             (None, 35, 35, 96)   83040       activation_640[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_642 (Conv2D)             (None, 35, 35, 32)   6176        average_pooling2d_60[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_636 (BatchN (None, 35, 35, 64)   192         conv2d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_638 (BatchN (None, 35, 35, 64)   192         conv2d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_641 (BatchN (None, 35, 35, 96)   288         conv2d_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_642 (BatchN (None, 35, 35, 32)   96          conv2d_642[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_636 (Activation)     (None, 35, 35, 64)   0           batch_normalization_636[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_638 (Activation)     (None, 35, 35, 64)   0           batch_normalization_638[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_641 (Activation)     (None, 35, 35, 96)   0           batch_normalization_641[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_642 (Activation)     (None, 35, 35, 32)   0           batch_normalization_642[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 35, 35, 256)  0           activation_636[0][0]             \n",
      "                                                                 activation_638[0][0]             \n",
      "                                                                 activation_641[0][0]             \n",
      "                                                                 activation_642[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_646 (Conv2D)             (None, 35, 35, 64)   16448       concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_646 (BatchN (None, 35, 35, 64)   192         conv2d_646[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_646 (Activation)     (None, 35, 35, 64)   0           batch_normalization_646[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_644 (Conv2D)             (None, 35, 35, 48)   12336       concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_647 (Conv2D)             (None, 35, 35, 96)   55392       activation_646[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_644 (BatchN (None, 35, 35, 48)   144         conv2d_644[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_647 (BatchN (None, 35, 35, 96)   288         conv2d_647[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_644 (Activation)     (None, 35, 35, 48)   0           batch_normalization_644[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_647 (Activation)     (None, 35, 35, 96)   0           batch_normalization_647[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_61 (AveragePo (None, 35, 35, 256)  0           concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_643 (Conv2D)             (None, 35, 35, 64)   16448       concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_645 (Conv2D)             (None, 35, 35, 64)   76864       activation_644[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_648 (Conv2D)             (None, 35, 35, 96)   83040       activation_647[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_649 (Conv2D)             (None, 35, 35, 32)   8224        average_pooling2d_61[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_643 (BatchN (None, 35, 35, 64)   192         conv2d_643[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_645 (BatchN (None, 35, 35, 64)   192         conv2d_645[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_648 (BatchN (None, 35, 35, 96)   288         conv2d_648[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_649 (BatchN (None, 35, 35, 32)   96          conv2d_649[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_643 (Activation)     (None, 35, 35, 64)   0           batch_normalization_643[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_645 (Activation)     (None, 35, 35, 64)   0           batch_normalization_645[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_648 (Activation)     (None, 35, 35, 96)   0           batch_normalization_648[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_649 (Activation)     (None, 35, 35, 32)   0           batch_normalization_649[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 35, 35, 256)  0           activation_643[0][0]             \n",
      "                                                                 activation_645[0][0]             \n",
      "                                                                 activation_648[0][0]             \n",
      "                                                                 activation_649[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_653 (Conv2D)             (None, 35, 35, 64)   16448       concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_653 (BatchN (None, 35, 35, 64)   192         conv2d_653[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_653 (Activation)     (None, 35, 35, 64)   0           batch_normalization_653[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_651 (Conv2D)             (None, 35, 35, 48)   12336       concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_654 (Conv2D)             (None, 35, 35, 96)   55392       activation_653[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_651 (BatchN (None, 35, 35, 48)   144         conv2d_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_654 (BatchN (None, 35, 35, 96)   288         conv2d_654[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_651 (Activation)     (None, 35, 35, 48)   0           batch_normalization_651[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_654 (Activation)     (None, 35, 35, 96)   0           batch_normalization_654[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_62 (AveragePo (None, 35, 35, 256)  0           concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_650 (Conv2D)             (None, 35, 35, 64)   16448       concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_652 (Conv2D)             (None, 35, 35, 64)   76864       activation_651[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_655 (Conv2D)             (None, 35, 35, 96)   83040       activation_654[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_656 (Conv2D)             (None, 35, 35, 32)   8224        average_pooling2d_62[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_650 (BatchN (None, 35, 35, 64)   192         conv2d_650[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_652 (BatchN (None, 35, 35, 64)   192         conv2d_652[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_655 (BatchN (None, 35, 35, 96)   288         conv2d_655[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_656 (BatchN (None, 35, 35, 32)   96          conv2d_656[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_650 (Activation)     (None, 35, 35, 64)   0           batch_normalization_650[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_652 (Activation)     (None, 35, 35, 64)   0           batch_normalization_652[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_655 (Activation)     (None, 35, 35, 96)   0           batch_normalization_655[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_656 (Activation)     (None, 35, 35, 32)   0           batch_normalization_656[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 35, 35, 256)  0           activation_650[0][0]             \n",
      "                                                                 activation_652[0][0]             \n",
      "                                                                 activation_655[0][0]             \n",
      "                                                                 activation_656[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_658 (Conv2D)             (None, 35, 35, 64)   16448       concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_658 (BatchN (None, 35, 35, 64)   192         conv2d_658[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_658 (Activation)     (None, 35, 35, 64)   0           batch_normalization_658[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_659 (Conv2D)             (None, 35, 35, 96)   55392       activation_658[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_659 (BatchN (None, 35, 35, 96)   288         conv2d_659[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_659 (Activation)     (None, 35, 35, 96)   0           batch_normalization_659[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_657 (Conv2D)             (None, 17, 17, 384)  885120      concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_660 (Conv2D)             (None, 17, 17, 96)   83040       activation_659[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_657 (BatchN (None, 17, 17, 384)  1152        conv2d_657[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_660 (BatchN (None, 17, 17, 96)   288         conv2d_660[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_657 (Activation)     (None, 17, 17, 384)  0           batch_normalization_657[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_660 (Activation)     (None, 17, 17, 96)   0           batch_normalization_660[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling2D) (None, 17, 17, 256)  0           concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 17, 17, 736)  0           activation_657[0][0]             \n",
      "                                                                 activation_660[0][0]             \n",
      "                                                                 max_pooling2d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_665 (Conv2D)             (None, 17, 17, 128)  94336       concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_665 (BatchN (None, 17, 17, 128)  384         conv2d_665[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_665 (Activation)     (None, 17, 17, 128)  0           batch_normalization_665[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_666 (Conv2D)             (None, 17, 17, 128)  114816      activation_665[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_666 (BatchN (None, 17, 17, 128)  384         conv2d_666[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_666 (Activation)     (None, 17, 17, 128)  0           batch_normalization_666[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_662 (Conv2D)             (None, 17, 17, 128)  94336       concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_667 (Conv2D)             (None, 17, 17, 128)  114816      activation_666[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_662 (BatchN (None, 17, 17, 128)  384         conv2d_662[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_667 (BatchN (None, 17, 17, 128)  384         conv2d_667[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_662 (Activation)     (None, 17, 17, 128)  0           batch_normalization_662[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_667 (Activation)     (None, 17, 17, 128)  0           batch_normalization_667[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_663 (Conv2D)             (None, 17, 17, 128)  114816      activation_662[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_668 (Conv2D)             (None, 17, 17, 128)  114816      activation_667[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_663 (BatchN (None, 17, 17, 128)  384         conv2d_663[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_668 (BatchN (None, 17, 17, 128)  384         conv2d_668[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_663 (Activation)     (None, 17, 17, 128)  0           batch_normalization_663[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_668 (Activation)     (None, 17, 17, 128)  0           batch_normalization_668[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_63 (AveragePo (None, 17, 17, 736)  0           concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_661 (Conv2D)             (None, 17, 17, 192)  141504      concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_664 (Conv2D)             (None, 17, 17, 192)  172224      activation_663[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_669 (Conv2D)             (None, 17, 17, 192)  172224      activation_668[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_670 (Conv2D)             (None, 17, 17, 192)  141504      average_pooling2d_63[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_661 (BatchN (None, 17, 17, 192)  576         conv2d_661[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_664 (BatchN (None, 17, 17, 192)  576         conv2d_664[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_669 (BatchN (None, 17, 17, 192)  576         conv2d_669[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_670 (BatchN (None, 17, 17, 192)  576         conv2d_670[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_661 (Activation)     (None, 17, 17, 192)  0           batch_normalization_661[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_664 (Activation)     (None, 17, 17, 192)  0           batch_normalization_664[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_669 (Activation)     (None, 17, 17, 192)  0           batch_normalization_669[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_670 (Activation)     (None, 17, 17, 192)  0           batch_normalization_670[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 17, 17, 768)  0           activation_661[0][0]             \n",
      "                                                                 activation_664[0][0]             \n",
      "                                                                 activation_669[0][0]             \n",
      "                                                                 activation_670[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_675 (Conv2D)             (None, 17, 17, 128)  98432       concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_675 (BatchN (None, 17, 17, 128)  384         conv2d_675[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_675 (Activation)     (None, 17, 17, 128)  0           batch_normalization_675[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_676 (Conv2D)             (None, 17, 17, 128)  114816      activation_675[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_676 (BatchN (None, 17, 17, 128)  384         conv2d_676[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_676 (Activation)     (None, 17, 17, 128)  0           batch_normalization_676[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_672 (Conv2D)             (None, 17, 17, 128)  98432       concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_677 (Conv2D)             (None, 17, 17, 128)  114816      activation_676[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_672 (BatchN (None, 17, 17, 128)  384         conv2d_672[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_677 (BatchN (None, 17, 17, 128)  384         conv2d_677[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_672 (Activation)     (None, 17, 17, 128)  0           batch_normalization_672[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_677 (Activation)     (None, 17, 17, 128)  0           batch_normalization_677[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_673 (Conv2D)             (None, 17, 17, 128)  114816      activation_672[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_678 (Conv2D)             (None, 17, 17, 128)  114816      activation_677[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_673 (BatchN (None, 17, 17, 128)  384         conv2d_673[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_678 (BatchN (None, 17, 17, 128)  384         conv2d_678[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_673 (Activation)     (None, 17, 17, 128)  0           batch_normalization_673[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_678 (Activation)     (None, 17, 17, 128)  0           batch_normalization_678[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_64 (AveragePo (None, 17, 17, 768)  0           concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_671 (Conv2D)             (None, 17, 17, 192)  147648      concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_674 (Conv2D)             (None, 17, 17, 192)  172224      activation_673[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_679 (Conv2D)             (None, 17, 17, 192)  172224      activation_678[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_680 (Conv2D)             (None, 17, 17, 192)  147648      average_pooling2d_64[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_671 (BatchN (None, 17, 17, 192)  576         conv2d_671[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_674 (BatchN (None, 17, 17, 192)  576         conv2d_674[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_679 (BatchN (None, 17, 17, 192)  576         conv2d_679[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_680 (BatchN (None, 17, 17, 192)  576         conv2d_680[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_671 (Activation)     (None, 17, 17, 192)  0           batch_normalization_671[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_674 (Activation)     (None, 17, 17, 192)  0           batch_normalization_674[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_679 (Activation)     (None, 17, 17, 192)  0           batch_normalization_679[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_680 (Activation)     (None, 17, 17, 192)  0           batch_normalization_680[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 17, 17, 768)  0           activation_671[0][0]             \n",
      "                                                                 activation_674[0][0]             \n",
      "                                                                 activation_679[0][0]             \n",
      "                                                                 activation_680[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_685 (Conv2D)             (None, 17, 17, 128)  98432       concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_685 (BatchN (None, 17, 17, 128)  384         conv2d_685[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_685 (Activation)     (None, 17, 17, 128)  0           batch_normalization_685[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_686 (Conv2D)             (None, 17, 17, 128)  114816      activation_685[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_686 (BatchN (None, 17, 17, 128)  384         conv2d_686[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_686 (Activation)     (None, 17, 17, 128)  0           batch_normalization_686[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_682 (Conv2D)             (None, 17, 17, 128)  98432       concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_687 (Conv2D)             (None, 17, 17, 128)  114816      activation_686[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_682 (BatchN (None, 17, 17, 128)  384         conv2d_682[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_687 (BatchN (None, 17, 17, 128)  384         conv2d_687[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_682 (Activation)     (None, 17, 17, 128)  0           batch_normalization_682[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_687 (Activation)     (None, 17, 17, 128)  0           batch_normalization_687[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_683 (Conv2D)             (None, 17, 17, 128)  114816      activation_682[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_688 (Conv2D)             (None, 17, 17, 128)  114816      activation_687[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_683 (BatchN (None, 17, 17, 128)  384         conv2d_683[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_688 (BatchN (None, 17, 17, 128)  384         conv2d_688[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_683 (Activation)     (None, 17, 17, 128)  0           batch_normalization_683[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_688 (Activation)     (None, 17, 17, 128)  0           batch_normalization_688[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_65 (AveragePo (None, 17, 17, 768)  0           concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_681 (Conv2D)             (None, 17, 17, 192)  147648      concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_684 (Conv2D)             (None, 17, 17, 192)  172224      activation_683[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_689 (Conv2D)             (None, 17, 17, 192)  172224      activation_688[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_690 (Conv2D)             (None, 17, 17, 192)  147648      average_pooling2d_65[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_681 (BatchN (None, 17, 17, 192)  576         conv2d_681[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_684 (BatchN (None, 17, 17, 192)  576         conv2d_684[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_689 (BatchN (None, 17, 17, 192)  576         conv2d_689[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_690 (BatchN (None, 17, 17, 192)  576         conv2d_690[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_681 (Activation)     (None, 17, 17, 192)  0           batch_normalization_681[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_684 (Activation)     (None, 17, 17, 192)  0           batch_normalization_684[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_689 (Activation)     (None, 17, 17, 192)  0           batch_normalization_689[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_690 (Activation)     (None, 17, 17, 192)  0           batch_normalization_690[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 17, 17, 768)  0           activation_681[0][0]             \n",
      "                                                                 activation_684[0][0]             \n",
      "                                                                 activation_689[0][0]             \n",
      "                                                                 activation_690[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_695 (Conv2D)             (None, 17, 17, 128)  98432       concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_695 (BatchN (None, 17, 17, 128)  384         conv2d_695[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_695 (Activation)     (None, 17, 17, 128)  0           batch_normalization_695[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_696 (Conv2D)             (None, 17, 17, 128)  114816      activation_695[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_696 (BatchN (None, 17, 17, 128)  384         conv2d_696[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_696 (Activation)     (None, 17, 17, 128)  0           batch_normalization_696[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_692 (Conv2D)             (None, 17, 17, 128)  98432       concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_697 (Conv2D)             (None, 17, 17, 128)  114816      activation_696[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_692 (BatchN (None, 17, 17, 128)  384         conv2d_692[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_697 (BatchN (None, 17, 17, 128)  384         conv2d_697[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_692 (Activation)     (None, 17, 17, 128)  0           batch_normalization_692[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_697 (Activation)     (None, 17, 17, 128)  0           batch_normalization_697[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_693 (Conv2D)             (None, 17, 17, 128)  114816      activation_692[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_698 (Conv2D)             (None, 17, 17, 128)  114816      activation_697[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_693 (BatchN (None, 17, 17, 128)  384         conv2d_693[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_698 (BatchN (None, 17, 17, 128)  384         conv2d_698[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_693 (Activation)     (None, 17, 17, 128)  0           batch_normalization_693[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_698 (Activation)     (None, 17, 17, 128)  0           batch_normalization_698[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_66 (AveragePo (None, 17, 17, 768)  0           concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_691 (Conv2D)             (None, 17, 17, 192)  147648      concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_694 (Conv2D)             (None, 17, 17, 192)  172224      activation_693[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_699 (Conv2D)             (None, 17, 17, 192)  172224      activation_698[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_700 (Conv2D)             (None, 17, 17, 192)  147648      average_pooling2d_66[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_691 (BatchN (None, 17, 17, 192)  576         conv2d_691[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_694 (BatchN (None, 17, 17, 192)  576         conv2d_694[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_699 (BatchN (None, 17, 17, 192)  576         conv2d_699[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_700 (BatchN (None, 17, 17, 192)  576         conv2d_700[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_691 (Activation)     (None, 17, 17, 192)  0           batch_normalization_691[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_694 (Activation)     (None, 17, 17, 192)  0           batch_normalization_694[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_699 (Activation)     (None, 17, 17, 192)  0           batch_normalization_699[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_700 (Activation)     (None, 17, 17, 192)  0           batch_normalization_700[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 17, 17, 768)  0           activation_691[0][0]             \n",
      "                                                                 activation_694[0][0]             \n",
      "                                                                 activation_699[0][0]             \n",
      "                                                                 activation_700[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_703 (Conv2D)             (None, 17, 17, 192)  147648      concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_703 (BatchN (None, 17, 17, 192)  576         conv2d_703[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_703 (Activation)     (None, 17, 17, 192)  0           batch_normalization_703[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_704 (Conv2D)             (None, 17, 17, 192)  258240      activation_703[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_704 (BatchN (None, 17, 17, 192)  576         conv2d_704[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_704 (Activation)     (None, 17, 17, 192)  0           batch_normalization_704[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_701 (Conv2D)             (None, 17, 17, 192)  147648      concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_705 (Conv2D)             (None, 17, 17, 192)  258240      activation_704[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_701 (BatchN (None, 17, 17, 192)  576         conv2d_701[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_705 (BatchN (None, 17, 17, 192)  576         conv2d_705[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_701 (Activation)     (None, 17, 17, 192)  0           batch_normalization_701[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_705 (Activation)     (None, 17, 17, 192)  0           batch_normalization_705[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_702 (Conv2D)             (None, 8, 8, 320)    553280      activation_701[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_706 (Conv2D)             (None, 8, 8, 192)    331968      activation_705[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_702 (BatchN (None, 8, 8, 320)    960         conv2d_702[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_706 (BatchN (None, 8, 8, 192)    576         conv2d_706[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_702 (Activation)     (None, 8, 8, 320)    0           batch_normalization_702[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_706 (Activation)     (None, 8, 8, 192)    0           batch_normalization_706[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, 8, 8, 768)    0           concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 8, 8, 1280)   0           activation_702[0][0]             \n",
      "                                                                 activation_706[0][0]             \n",
      "                                                                 max_pooling2d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_711 (Conv2D)             (None, 8, 8, 448)    573888      concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_711 (BatchN (None, 8, 8, 448)    1344        conv2d_711[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_711 (Activation)     (None, 8, 8, 448)    0           batch_normalization_711[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_708 (Conv2D)             (None, 8, 8, 384)    491904      concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_712 (Conv2D)             (None, 8, 8, 384)    1548672     activation_711[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_708 (BatchN (None, 8, 8, 384)    1152        conv2d_708[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_712 (BatchN (None, 8, 8, 384)    1152        conv2d_712[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_708 (Activation)     (None, 8, 8, 384)    0           batch_normalization_708[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_712 (Activation)     (None, 8, 8, 384)    0           batch_normalization_712[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_709 (Conv2D)             (None, 8, 8, 384)    442752      activation_708[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_710 (Conv2D)             (None, 8, 8, 384)    442752      activation_708[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_713 (Conv2D)             (None, 8, 8, 384)    442752      activation_712[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_714 (Conv2D)             (None, 8, 8, 384)    442752      activation_712[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_67 (AveragePo (None, 8, 8, 1280)   0           concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_707 (Conv2D)             (None, 8, 8, 320)    409920      concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_709 (BatchN (None, 8, 8, 384)    1152        conv2d_709[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_710 (BatchN (None, 8, 8, 384)    1152        conv2d_710[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_713 (BatchN (None, 8, 8, 384)    1152        conv2d_713[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_714 (BatchN (None, 8, 8, 384)    1152        conv2d_714[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_715 (Conv2D)             (None, 8, 8, 192)    245952      average_pooling2d_67[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_707 (BatchN (None, 8, 8, 320)    960         conv2d_707[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_709 (Activation)     (None, 8, 8, 384)    0           batch_normalization_709[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_710 (Activation)     (None, 8, 8, 384)    0           batch_normalization_710[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_713 (Activation)     (None, 8, 8, 384)    0           batch_normalization_713[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_714 (Activation)     (None, 8, 8, 384)    0           batch_normalization_714[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_715 (BatchN (None, 8, 8, 192)    576         conv2d_715[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_707 (Activation)     (None, 8, 8, 320)    0           batch_normalization_707[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 8, 8, 768)    0           activation_709[0][0]             \n",
      "                                                                 activation_710[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 8, 8, 768)    0           activation_713[0][0]             \n",
      "                                                                 activation_714[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_715 (Activation)     (None, 8, 8, 192)    0           batch_normalization_715[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 8, 8, 2048)   0           activation_707[0][0]             \n",
      "                                                                 concatenate_105[0][0]            \n",
      "                                                                 concatenate_106[0][0]            \n",
      "                                                                 activation_715[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_720 (Conv2D)             (None, 8, 8, 448)    917952      concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_720 (BatchN (None, 8, 8, 448)    1344        conv2d_720[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_720 (Activation)     (None, 8, 8, 448)    0           batch_normalization_720[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_717 (Conv2D)             (None, 8, 8, 384)    786816      concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_721 (Conv2D)             (None, 8, 8, 384)    1548672     activation_720[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_717 (BatchN (None, 8, 8, 384)    1152        conv2d_717[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_721 (BatchN (None, 8, 8, 384)    1152        conv2d_721[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_717 (Activation)     (None, 8, 8, 384)    0           batch_normalization_717[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_721 (Activation)     (None, 8, 8, 384)    0           batch_normalization_721[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_718 (Conv2D)             (None, 8, 8, 384)    442752      activation_717[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_719 (Conv2D)             (None, 8, 8, 384)    442752      activation_717[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_722 (Conv2D)             (None, 8, 8, 384)    442752      activation_721[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_723 (Conv2D)             (None, 8, 8, 384)    442752      activation_721[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_68 (AveragePo (None, 8, 8, 2048)   0           concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_716 (Conv2D)             (None, 8, 8, 320)    655680      concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_718 (BatchN (None, 8, 8, 384)    1152        conv2d_718[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_719 (BatchN (None, 8, 8, 384)    1152        conv2d_719[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_722 (BatchN (None, 8, 8, 384)    1152        conv2d_722[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_723 (BatchN (None, 8, 8, 384)    1152        conv2d_723[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_724 (Conv2D)             (None, 8, 8, 192)    393408      average_pooling2d_68[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_716 (BatchN (None, 8, 8, 320)    960         conv2d_716[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_718 (Activation)     (None, 8, 8, 384)    0           batch_normalization_718[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_719 (Activation)     (None, 8, 8, 384)    0           batch_normalization_719[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_722 (Activation)     (None, 8, 8, 384)    0           batch_normalization_722[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_723 (Activation)     (None, 8, 8, 384)    0           batch_normalization_723[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_724 (BatchN (None, 8, 8, 192)    576         conv2d_724[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_716 (Activation)     (None, 8, 8, 320)    0           batch_normalization_716[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 8, 8, 768)    0           activation_718[0][0]             \n",
      "                                                                 activation_719[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 8, 8, 768)    0           activation_722[0][0]             \n",
      "                                                                 activation_723[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_724 (Activation)     (None, 8, 8, 192)    0           batch_normalization_724[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 8, 8, 2048)   0           activation_716[0][0]             \n",
      "                                                                 concatenate_108[0][0]            \n",
      "                                                                 concatenate_109[0][0]            \n",
      "                                                                 activation_724[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 22,078,280\n",
      "Trainable params: 22,045,512\n",
      "Non-trainable params: 32,768\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-707f38ec233f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# plot model architecture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inception_model_3.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sorav singla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \"\"\"\n\u001b[0;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[1;32m--> 240\u001b[1;33m                        expand_nested, dpi)\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sorav singla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sorav singla\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         raise ImportError(\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[1;34m'Failed to import `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[1;34m'Please install `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
